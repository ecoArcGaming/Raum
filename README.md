## Raum
Spin-off project with the MIT Assistive Tech Club, this app is built to navigate visually-inpaired users to certain objects using spatial sound. 

It includes accessibility features such as
- text-to-speech input
- voice-over during object recognition 
- spatial hints for locating (supports the apple Dynamic Head Tracking feature on applicable devices)
- start-over with gesture

It is built with a simple iOS native pipeline, integrating coreML, ARkit, and NLEmbedding. Integrated with HRTF (head-related transfer function) to ensure a smooth spatial experience. Hoping to personalize this in the future but the iOS framework is unfortunately too rigid for that. 